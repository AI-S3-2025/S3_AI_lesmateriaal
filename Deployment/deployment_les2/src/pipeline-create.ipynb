{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756667112547
        }
      },
      "outputs": [],
      "source": [
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "credential = DefaultAzureCredential()  # Portable, works both in interactive and automated workloads\n",
        "ml_client = MLClient.from_config(credential=credential)  # Load config from current workspace (only works on personal compute)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756667115356
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "dataset = Data(\n",
        "    name=\"ames-housing-raw\",\n",
        "    description=\"Raw CSV of Ames Housing dataset\",\n",
        "    path=\"AmesHousing.csv\",  # relative to notebook path\n",
        "    type=AssetTypes.URI_FILE,\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Pipeline components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 1. Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756667115436
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import command, Input, Output, dsl\n",
        "\n",
        "# Convenience, as we'll reuse it in many components.\n",
        "SKLEARN_ENV = \"azureml://registries/azureml/environments/sklearn-1.5/labels/latest\"         # Curated Environment includes Scikit-learn for ML logic\n",
        "ML_SDK_ENV = \"azureml://registries/azureml/environments/python-sdk-v2/labels/latest\"        # Curated Environment includes AzureML SDK for API access\n",
        "\n",
        "split_component = command(\n",
        "    code=\"./stages\",                                # Directory hosting the component's code base. Becomes the working directory\n",
        "    command=\"python split.py \" \\\n",
        "                \"--input_data ${{inputs.input_data}} \" \\\n",
        "                \"--test_size ${{inputs.test_size}} \" \\\n",
        "                \"--random_state ${{inputs.random_state}} \" \\\n",
        "                \"--X_train ${{outputs.X_train}} \" \\\n",
        "                \"--y_train ${{outputs.y_train}} \" \\\n",
        "                \"--X_test ${{outputs.X_test}} \" \\\n",
        "                \"--y_test ${{outputs.y_test}}\",     # As this is a command components, we need to invoke the Python script\n",
        "    environment=SKLEARN_ENV,                        # Needed, as Scikit learn functionality is used in the Python file\n",
        "    display_name=\"split\",\n",
        "    inputs={                                        # Input slots\n",
        "        \"input_data\": Input(type=\"uri_file\"),\n",
        "        \"test_size\": Input(type=\"string\"),          # float-type is not yet supported by the SDK\n",
        "        \"random_state\": Input(type=\"string\")        # int-type is not yet supported by the SDK\n",
        "    },\n",
        "    outputs={                                       # Output slots\n",
        "        \"X_train\": Output(type=\"uri_file\"),\n",
        "        \"y_train\": Output(type=\"uri_file\"),\n",
        "        \"X_test\" : Output(type=\"uri_file\"),\n",
        "        \"y_test\" : Output(type=\"uri_file\")\n",
        "\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 2. Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756667115499
        }
      },
      "outputs": [],
      "source": [
        "prep_component = command(\n",
        "    code=\"./stages\",    # Will also upload the preprocessing.py module\n",
        "    command=\"python prep.py \" \\\n",
        "                \"--raw_data ${{inputs.raw_data}} \" \\\n",
        "                \"$[[--xform_params_in ${{inputs.xform_params_in}}]] \"\\\n",
        "                \"--prepped_data ${{outputs.prepped_data}} \" \\\n",
        "                \"--xform_params_out ${{outputs.xform_params_out}}\", # $[[]] allows specifying optional parameters. If missing, the whole flag is ommited\n",
        "    environment=SKLEARN_ENV,\n",
        "    display_name=\"prep\",\n",
        "    inputs={\n",
        "        \"raw_data\": Input(type=\"uri_file\"),                         # Instead of hardcoding the input data, this allows parameterization for reusablilty\n",
        "        \"xform_params_in\": Input(type=\"uri_file\", optional=True)    # Preprocessing is not stateless, so we might need parameters derived during training\n",
        "    },\n",
        "    outputs={\n",
        "        \"prepped_data\": Output(type=\"uri_file\"),\n",
        "        \"xform_params_out\": Output(type=\"uri_file\")\n",
        "\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 3. Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756667115566
        }
      },
      "outputs": [],
      "source": [
        "model_asset_name = \"minimal-model\"  # Enforces consitent model asset name\n",
        "\n",
        "train_component = command(\n",
        "    code=\"./stages\",\n",
        "    command=\"python train.py \" \\\n",
        "                \"--X ${{inputs.X}} \" \\\n",
        "                \"--y ${{inputs.y}} \" \\\n",
        "                \"--xform_params ${{inputs.xform_params}} \" \\\n",
        "                \"--model_path ${{outputs.model_path}}\",\n",
        "    environment=SKLEARN_ENV,\n",
        "    display_name=\"train-model\",\n",
        "    inputs={\n",
        "        \"X\": Input(type=\"uri_file\"),\n",
        "        \"y\": Input(type=\"uri_file\"),\n",
        "        \"xform_params\": Input(type=\"uri_file\"),\n",
        "    },\n",
        "    outputs={\n",
        "        \"model_path\": Output(type=\"custom_model\", mode=\"upload\", name=\"minimal-model\")  # custom_model output will automatically register the model as a directory\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 4. deploy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756667115633
        }
      },
      "outputs": [],
      "source": [
        "deploy_component = command(\n",
        "    code=\"./stages\",    # Will also include score.py, making it available for the deployment script\n",
        "    command=\"python deploy.py \" \\\n",
        "                \"--model_name ${{inputs.model_name}} \" \\\n",
        "                \"--endpoint_name ${{inputs.endpoint_name}} \" \\\n",
        "                \"--example_payload ${{outputs.example_payload}}\",\n",
        "    environment=ML_SDK_ENV,\n",
        "    display_name=\"deploy-model\",\n",
        "    inputs={\n",
        "        \"model_path\": Input(type=\"custom_model\"),       # Forces this step to wait for model registration, but is not used in the script\n",
        "        \"model_name\": Input(type=\"string\"),\n",
        "        \"endpoint_name\": Input(type=\"string\"),\n",
        "    },\n",
        "    outputs={\n",
        "        \"example_payload\": Output(type=\"uri_file\")      # Needed to create a data dependency (added for pedagogical reasons)\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 5. test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756667115703
        }
      },
      "outputs": [],
      "source": [
        "test_component = command(\n",
        "    code=\"./stages\",\n",
        "    command=\"python test.py --endpoint_name ${{inputs.endpoint_name}} --example_payload ${{inputs.example_payload}}\",\n",
        "    environment=\"azureml://registries/azureml/environments/python-sdk-v2/versions/31\",\n",
        "    compute=\"mlops-cluster\",\n",
        "    display_name=\"test-endpoint\",\n",
        "    inputs={\n",
        "        \"endpoint_name\": Input(type=\"string\"),\n",
        "        \"example_payload\": Input(type=\"uri_file\"),    # Needed to create a data dependency (added for pedagogical reasons)\n",
        "\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 6. Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756667115761
        }
      },
      "outputs": [],
      "source": [
        "evaluate_component = command(\n",
        "    code=\"./stages\",\n",
        "    command=\"python evaluate.py \" \\\n",
        "                \"--model_path ${{inputs.model_path}} \" \\\n",
        "                \"--X ${{inputs.X}} \" \\\n",
        "                \"--y ${{inputs.y}} \" \\\n",
        "                \"--metrics ${{outputs.metrics}}\",\n",
        "    environment=SKLEARN_ENV,\n",
        "    display_name=\"evaluate model\",\n",
        "    inputs={\n",
        "        \"model_path\": Input(type=\"custom_model\"),\n",
        "        \"X\": Input(type=\"uri_file\"),\n",
        "        \"y\": Input(type=\"uri_file\")\n",
        "    },\n",
        "    outputs={\n",
        "        \"metrics\": Output(type=\"uri_file\")\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 7. Tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756667115824
        }
      },
      "outputs": [],
      "source": [
        "tag_component = command(\n",
        "    code=\"./stages\",\n",
        "    command=\"python tag.py \" \\\n",
        "                \"--model_name ${{inputs.model_name}} \" \\\n",
        "                \"--metrics ${{inputs.metrics}}\",\n",
        "    environment=ML_SDK_ENV,\n",
        "    display_name=\"tag model\",\n",
        "    inputs={\n",
        "        \"model_name\": Input(type=\"string\"),\n",
        "        \"metrics\": Input(type=\"uri_file\")\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Samenstellen pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756667115890
        }
      },
      "outputs": [],
      "source": [
        "@dsl.pipeline()         # The job-name will default to the name of the function, experiment name will default to name of the directory.\n",
        "def train_and_deploy(dataset_uri, model_name, endpoint_name):\n",
        "    split = split_component(\n",
        "        input_data=dataset_uri,\n",
        "        test_size=\"0.2\",              # Withhold 20% of the dataset as test set\n",
        "        random_state=\"42\"             # Fixing the random_state makes the process deterministic. ideal for reproducibility during development, but unsuitable for production\n",
        "    )\n",
        "    prep_train = prep_component(\n",
        "        raw_data=split.outputs[\"X_train\"]\n",
        "    )\n",
        "    prep_test = prep_component(\n",
        "        raw_data=split.outputs[\"X_test\"],\n",
        "        xform_params_in=prep_train.outputs[\"xform_params_out\"]\n",
        "    )\n",
        "    train = train_component(\n",
        "        X=prep_train.outputs[\"prepped_data\"],\n",
        "        y=split.outputs[\"y_train\"],\n",
        "        xform_params=prep_train.outputs[\"xform_params_out\"],\n",
        "    )\n",
        "    evaluate = evaluate_component(\n",
        "        model_path=train.outputs[\"model_path\"],\n",
        "        X=prep_test.outputs[\"prepped_data\"],\n",
        "        y=split.outputs[\"y_test\"],\n",
        "    )\n",
        "    tag = tag_component(\n",
        "        model_name=model_name,\n",
        "        metrics=evaluate.outputs[\"metrics\"]\n",
        "    )\n",
        "    deploy = deploy_component(  # For demonstration purpose only. In production-grade environments, deployments are often managed in separate pipelines (or CI/CD). \n",
        "        model_path=train.outputs[\"model_path\"],  # Needed to enforce dependency on train-component, but not actually used\n",
        "        model_name=model_name,\n",
        "        endpoint_name=endpoint_name\n",
        "    )\n",
        "    test = test_component(\n",
        "        endpoint_name=endpoint_name,\n",
        "        example_payload=deploy.outputs[\"example_payload\"],\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Submitten pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756667129269
        }
      },
      "outputs": [],
      "source": [
        "# model_asset_name was already defined above\n",
        "endpoint_name = \"sklearn-endpoint\"\n",
        "ames_housing_data_asset = Input(type=\"uri_file\", path=\"azureml:ames-housing-raw:1\")\n",
        "\n",
        "train_and_deploy_job = train_and_deploy(ames_housing_data_asset, model_asset_name, endpoint_name)\n",
        "train_and_deploy_job.settings.default_compute = \"mlops-cluster\" # Specifies the default cluster for each component. (Can be overriden per component)\n",
        "\n",
        "ml_client.jobs.create_or_update(train_and_deploy_job)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
